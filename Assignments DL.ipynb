{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7079b2e6",
   "metadata": {},
   "source": [
    "### Assignment 1\n",
    "\n",
    "Linear regression by using Deep Neural network: <br>\n",
    "Implement Boston housing price  predictionproblem by Linear regression using Deep Neural network. Use Boston House price predictiondataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704754e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 23.201763153076172\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# Normalize the input features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(x_train.shape[1],))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, verbose = 0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d98bcd",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "\n",
    "Binary classification using Deep Neural Networks Example: Classify movie reviews into\n",
    "positive\" reviews and \"negative\" reviews, just based on the text content of the reviews.\n",
    "Use IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6500c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 2s 27ms/step - loss: 0.6916 - accuracy: 0.6155\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.6846 - accuracy: 0.7099\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.6738 - accuracy: 0.7437\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.6600 - accuracy: 0.7465\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.6427 - accuracy: 0.7631\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.6241 - accuracy: 0.7720\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.6034 - accuracy: 0.7806\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.5837 - accuracy: 0.7935\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.5616 - accuracy: 0.8068\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.5442 - accuracy: 0.8118\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.8057\n",
      "Accuracy: 0.8057199716567993\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "\n",
    "# Preprocess the data by vectorizing the sequences\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=256)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, maxlen=256)\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(10000, 17),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=512)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf694ab",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "**Convolutional neural network (CNN):** Use MNIST Fashion Dataset and create a classifier to classify fashion clothing into\n",
    "categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26899dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 16s 8ms/step - loss: 4.4123 - accuracy: 0.7657\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8415\n",
      "Test accuracy: 0.8414999842643738\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the MNIST Fashion Dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    layers.Conv2D(10, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788718c",
   "metadata": {},
   "source": [
    "### Assignment 4\n",
    "\n",
    "Use the Google stock prices dataset and design a time \n",
    "seriesanalysis and prediction system using RNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
